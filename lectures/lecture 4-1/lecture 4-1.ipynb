{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530c9bc3-4226-4a72-a9a7-92475e8415af",
   "metadata": {},
   "source": [
    "logistic regression can be extended via the softmax function\n",
    "\n",
    "sigmoid function\n",
    "\n",
    "kNN returns the most frequent among the k nearest neighbors. \n",
    "\n",
    "now “most frequent” is across C ≥ 2 classes, not just C = \n",
    "\n",
    "SVMs are naturally binary, and can be extended, solving the C problem called the 'c binary' classifier\n",
    "    copy the data C times, changing labels other than 1 to 0 in the first copy, labels other than 2 to 0 in the second, and labels other than 3 to 0 in the third\n",
    "    Classify a new x by choosing the most-certain (non-zero) prediction, where “certainty\" is proportional to the signed distance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "608aed2d-4fc3-4ef1-af99-d37838009855",
   "metadata": {},
   "source": [
    "__11|_    |\n",
    "   \\|  *   |\n",
    "____|\\____|_____\n",
    "     | \\  |\n",
    " _22  |  \\ |   33_\n",
    " 2    |    |\n",
    "\n",
    "boundary \\ signed distance\n",
    "1s vs rest| +1/4\n",
    "2s vs rest| -1/2     the star (*) is a 1\n",
    "3s vs rest| -1/4\n",
    "\n",
    "most classification algos eiter are convertible to multiclass or sive a score with which we can use for one vs cost strategy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7fdc979-5f53-4cd9-8491-c7e47ad794de",
   "metadata": {},
   "source": [
    "One-Class Classification\n",
    "identifies one class for which we have training data from everything else. e.g. An IT department managing its computer network wants to detect anomalous traffic\n",
    "\n",
    "One-class Gaussian models the training data with the multivariate normal distribution (MND)\n",
    "A new input x is in the one class if fµ,Σ(x) is above an experimentally-decided threshold\n",
    "     _  _\n",
    "   /    \\\n",
    "_/_.|_.|__.|\\___\n",
    "threshold = ???\n",
    "\n",
    "\n",
    "fo gaussian mixture: np.quantile(a, q) with a=likelihoods and small q ∈ (0, 1).\n",
    "\n",
    "One-class k-means5\n",
    "computes d(x) as the minimum distance from a new x to each of k cluster centers. If d is less than a threshold, x is in the class\n",
    "\n",
    " One-class SVM either:\n",
    "– separates training examples from origin by a hyperplane, maximizing the distance from hyperplane to the origin; or\n",
    "– makes a (hyper-)spherical boundary around the data by minimizing its volume"
   ]
  },
  {
   "cell_type": "raw",
   "id": "264cb2d1-561d-4e01-9eb8-4803ad7a1f60",
   "metadata": {},
   "source": [
    "Transform each labeled example into several examples, each with one of the several original labels. Now we have a multiclass classification problem that can be solved with the\n",
    " stop and rest strategy. Add a threshold hyperparameter, chosen using validation\n",
    "data, and the label for each class scoring above the threshold is assigned to x.\n",
    "\n",
    "\n",
    "Other natural multiclass algorithms (decision tree, logistic regression) give a score\n",
    "for each class, so again each class above the threshold is assigned\n",
    "\n",
    "Where the number of values each label can take is small, we can convert a multi-label problem\n",
    "to a multi class problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
